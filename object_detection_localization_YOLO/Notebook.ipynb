{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c66539-2f3b-4e8f-8732-d8bfd031e5b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62263514-a600-47f2-9e94-57ed5ac74f7e",
   "metadata": {},
   "source": [
    "Weights & Biases (WandB) is a machine learning development platform that allows users to track and visualize various aspects of their model training process in real-time.<br>\n",
    "Link: https://wandb.ai/site\n",
    "\n",
    "In order to use this helpful platform, first, you need to sign up in the website with the provided link. <br>\n",
    "During the training you need to use your key-code to connect and see your online training results. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15b3936-18b8-48cc-8c94-296693e4fcdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (3.1.27)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (62.0.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (3.7.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (8.1.2)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp38-cp38-win_amd64.whl (11 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
      "     ------------------------------------ 215.6/215.6 KB 138.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from wandb) (3.20.0rc2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.4)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "     ------------------------------------- 143.1/143.1 KB 76.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=04d1693aab3cfb839e0a4319a5ef83a95c3bc941756d895ff41518ca866ef972\n",
      "  Stored in directory: c:\\users\\arminabd\\appdata\\local\\pip\\cache\\wheels\\4c\\8e\\7e\\72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, appdirs, urllib3, setproctitle, docker-pycreds, sentry-sdk, wandb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "Successfully installed appdirs-1.4.4 docker-pycreds-0.4.0 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 urllib3-1.26.16 wandb-0.15.8\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dfe11-af78-427e-93ab-be6ec83533f1",
   "metadata": {},
   "source": [
    "Ultralytics provides cutting-edge solutions for a wide range of AI tasks, including detection, segmentation, classification, tracking and pose estimation.<br>\n",
    "For this specific project, I employed the YOLO8 model developed by Ultralytics. <br>\n",
    "This model stands as the pinnacle of YOLO models, showcasing unparalleled performance and raising the bar in real-time detection and segmentation.<br>\n",
    "Link (website): https://ultralytics.com/\n",
    "Link (GitHub) : https://github.com/ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3984c56c-a1c1-4f83-8511-876e6fdf0717",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.161-py3-none-any.whl (609 kB)\n",
      "     ------------------------------------ 609.5/609.5 KB 286.3 kB/s eta 0:00:00\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ------------------------------------ 293.3/293.3 KB 452.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (3.5.1)\n",
      "Collecting torch>=1.8.0\n",
      "  Downloading torch-2.0.1-cp38-cp38-win_amd64.whl (172.4 MB)\n",
      "     ------------------------------------ 172.4/172.4 MB 584.9 kB/s eta 0:00:00\n",
      "Collecting numpy>=1.22.2\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 14.9/14.9 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting torchvision>=0.9.0\n",
      "  Downloading torchvision-0.15.2-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (4.64.0)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "     -------------------------------------- 38.1/38.1 MB 892.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (2.27.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (9.1.0)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from ultralytics) (1.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (4.31.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.1)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.7.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.7.4.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\decode_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ------------------------------------ 536.2/536.2 KB 415.4 kB/s eta 0:00:00\n",
      "Installing collected packages: py-cpuinfo, mpmath, sympy, numpy, filelock, torch, opencv-python, torchvision, seaborn, ultralytics\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1\n",
      "    Uninstalling torch-1.7.1:\n",
      "      Successfully uninstalled torch-1.7.1\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.10.1\n",
      "    Uninstalling seaborn-0.10.1:\n",
      "      Successfully uninstalled seaborn-0.10.1\n",
      "Successfully installed filelock-3.12.2 mpmath-1.3.0 numpy-1.24.4 opencv-python-4.8.0.76 py-cpuinfo-9.0.0 seaborn-0.12.2 sympy-1.12 torch-2.0.1 torchvision-0.15.2 ultralytics-8.0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.0 requires numpy~=1.19.2, but you have numpy 1.24.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac9647-9fff-4e2f-9127-ef135287c263",
   "metadata": {},
   "source": [
    "This version of numpy is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559a8391-4860-420d-834e-a8840000f848",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.4\n",
      "  Downloading numpy-1.23.4-cp38-cp38-win_amd64.whl (14.7 MB)\n",
      "     ---------------------------------------- 14.7/14.7 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\decode_env\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a9e4a-2aed-4151-9579-17985d7ae8e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f667234-f78a-4388-936a-3f8eecd4a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "import shutil\n",
    "from shutil import copytree, ignore_patterns\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6b0ea-6a44-411e-8a3c-b9a57816b149",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2a1f95-19a1-46c5-9f85-f86b99cfc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_txt(label_path,xml_file,class_dict,destination_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    x=root.find('filename').text\n",
    "    txt_file = x.replace('.jpg','.txt')\n",
    "    txt_file = os.path.join(destination_file,txt_file)\n",
    "    with open(txt_file,'w') as f:\n",
    "        for obj in root.findall('object'):\n",
    "            class_name = obj.find('name').text\n",
    "            if class_name not in class_dict:\n",
    "                continue\n",
    "            class_id = class_dict[class_name]\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = int(bbox.find('xmin').text)\n",
    "            xmax = int(bbox.find('xmax').text)\n",
    "            ymin = int(bbox.find('ymin').text)\n",
    "            ymax = int(bbox.find('ymax').text)\n",
    "            \n",
    "            image_width = int(root.find('size/width').text)\n",
    "            image_height = int(root.find('size/height').text)\n",
    "            \n",
    "            x_center = (xmin + xmax) / 2 / image_width if image_width != 0 else (xmin + xmax) / 2\n",
    "            y_center = (ymin + ymax) / 2 / image_height if image_height != 0 else (ymin + ymax) / 2\n",
    "            width = (xmax - xmin) / image_width if image_width != 0 else (xmax - xmin)\n",
    "            height = (ymax - ymin) / image_height if image_height != 0 else (ymax - ymin)\n",
    "             \n",
    "            line = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ef768-d3dc-48a5-909d-17d6b4bfcd96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset 1 (Fruits): Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d31863-56c4-49b2-a2ea-7a829382515a",
   "metadata": {},
   "source": [
    "__Hint:__ If the datasets are zipped, unzip those before running below cells <br>\n",
    "    \n",
    "This is a small dataset of fruits including the ground truth for the class of fruits of: <br>\n",
    "Apple: 0 <br>\n",
    "Banana: 1<br>\n",
    "Orange: 2<br>\n",
    "and, the box around each, _x1,x2,y1,and y2_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a7476-9ba8-4bec-8c2b-0613146ece65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \"\"\" Root path for the dataset 1 \"\"\"\n",
    "root_path = './datasets/dataset_fruits/'\n",
    "os.listdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f30f8c-d409-4cd5-ae17-90ef0162fb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \"\"\" Paths to the train & test data \"\"\"\n",
    "    \n",
    "train_data_path = os.path.join(root_path,'train_zip/train')\n",
    "test_data_path = os.path.join(root_path,'test_zip/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664c5b4-149c-404d-a315-4f9d22ed90ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \"\"\"All .xml and .jpg file names\"\"\"\n",
    "    \n",
    "train_data_description = os.listdir(train_data_path)\n",
    "test_data_description = os.listdir(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063cb14-8692-4c90-b471-46b1dd72910a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \"\"\"train_annotaion_file_paths and test_annotation_file_paths contains all .xml file paths\n",
    "   train_image_file_paths and test_image_file_paths contains all .jpg file paths\"\"\"\n",
    "    \n",
    "train_annotation_file_paths = [os.path.join(train_data_path,i) for i in train_data_description if '.xml' in i]\n",
    "train_image_file_paths = [os.path.join(train_data_path,i) for i in train_data_description if '.jpg' in i]\n",
    "\n",
    "test_annotation_file_paths = [os.path.join(test_data_path,i) for i in test_data_description if '.xml' in i]\n",
    "test_image_file_paths = [os.path.join(test_data_path,i) for i in test_data_description if '.jpg' in i]\n",
    "\n",
    "print(f'length of training Data {len(train_image_file_paths)}, length of test data {len(test_image_file_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83266e8-5bc9-49ec-b4df-a041c838c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Creating required directories to labels\"\"\"\n",
    "    \n",
    "for i in ['train/labels','test/labels']:\n",
    "    directory_name = os.path.join('./datasets/dataset_fruits/',i)\n",
    "    if os.path.exists(directory_name):\n",
    "        shutil.rmtree(directory_name)\n",
    "    os.makedirs(directory_name)\n",
    "    \n",
    "\"\"\"Copying all images to required directories\"\"\"\n",
    "copytree(train_data_path,'./datasets/dataset_fruits/train/images/',ignore = ignore_patterns('*.xml'))\n",
    "copytree(test_data_path,'./datasets/dataset_fruits/test/images/',ignore = ignore_patterns('*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467dc79e-1398-43db-8a15-eb1ce3ca4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'apple':0,'banana':1,'orange':2}\n",
    "dest_path = './datasets/dataset_fruits/train/labels/'\n",
    "for i in train_annotation_file_paths:\n",
    "    convert_xml_to_txt(train_data_path,i,class_dict,dest_path)\n",
    "dest_path = './datasets/dataset_fruits/test/labels/'\n",
    "for i in test_annotation_file_paths:\n",
    "    convert_xml_to_txt(test_data_path,i,class_dict,dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4182d-174d-45e1-8d4f-91ecd6777ec8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the pre-trained version of YOLO8 on Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35dca0-93d4-47e1-a0a4-691dcc92f7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \"\"\"yaml file path, you can check the file\"\"\"\n",
    "yaml_path = \"./data_FRUITS.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e0346-4a76-486d-a48e-dfb2c91ed4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccda94-890c-4a5d-9df4-754c8fedbbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Training model'''\n",
    "results = model.train(data=yaml_path, epochs=500, batch=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73a21a-6d81-4633-8519-65397f2a2cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd12ef-231c-4f41-8c13-7529b137a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the model'''\n",
    "model = YOLO('./train1/weights/best.pt')\n",
    "img_dict = {0:'apple',1:'banana',2:'orange'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86323e4-cd6e-446f-be63-602d5a18e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the images from each type of apples, bananas, oranges, and mixed fruits'''\n",
    "path_img = './datasets/dataset_fruits/test_zip/test/apple_87.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "colors = ['r','y','b']\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a43c19-f3e8-49c6-8d29-bcce182bd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = './datasets/dataset_fruits/test_zip/test/banana_89.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c3631-8f8f-4537-8de1-dd3330732726",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = './datasets/dataset_fruits/test_zip/test/orange_81.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        print(x1,confidence,label)\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad84ff-590a-444b-8781-31fa3525300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = './datasets/dataset_fruits/test_zip/test/mixed_22.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b49b37-eb5f-4843-ada0-34fda39d77fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset 2 (VOC): Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5f1dd-f714-476a-b90d-b52478c0624a",
   "metadata": {},
   "source": [
    "__Hint:__ If the datasets are zipped, unzip those before running below cells\n",
    "\n",
    "This is a huge dataset of indoor and outdoor images including the ground truth for 20 different classes of: <br>\n",
    "  0: aeroplane<br>\n",
    "  1: bicycle<br>\n",
    "  2: boat<br>\n",
    "  3: bus<br>\n",
    "  4: car<br>\n",
    "  5: motorbike<br>\n",
    "  6: train<br>\n",
    "  7: bird<br>\n",
    "  8: cat<br>\n",
    "  9: cow<br>\n",
    "  10: dog<br>\n",
    "  11: horse<br>\n",
    "  12: sheep<br>\n",
    "  13: person<br>\n",
    "  14: bottle<br>\n",
    "  15: chair<br>\n",
    "  16: dining table<br>\n",
    "  17: potted plant<br>\n",
    "  18: sofa<br>\n",
    "  19: tv/monitor<br>\n",
    "and, the box around each, _x1,x2,y1,and y2_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e4a30-2444-41c0-809d-bc0e3381a80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \"\"\" Root path for the dataset 1 \"\"\"\n",
    "root_path = './datasets/dataset_VOC/'\n",
    "os.listdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b4b2f-fde7-4cd4-82d1-c0d26be4a139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \"\"\" Paths to the train & test data \"\"\"\n",
    "    \n",
    "train_data_path = os.path.join(root_path,'train_zip/train')\n",
    "test_data_path = os.path.join(root_path,'test_zip/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72722033-2dfc-491f-a0a4-f8fda869ed75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \"\"\"All .xml and .jpg file names\"\"\"\n",
    "    \n",
    "train_data_description = os.listdir(train_data_path)\n",
    "test_data_description = os.listdir(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405cf60-8989-4cf8-bd36-54769121ee14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \"\"\"train_annotaion_file_paths and test_annotation_file_paths contains all .xml file paths\n",
    "   train_image_file_paths and test_image_file_paths contains all .jpg file paths\"\"\"\n",
    "    \n",
    "train_annotation_file_paths = [os.path.join(train_data_path,i) for i in train_data_description if '.xml' in i]\n",
    "train_image_file_paths = [os.path.join(train_data_path,i) for i in train_data_description if '.jpg' in i]\n",
    "\n",
    "test_annotation_file_paths = [os.path.join(test_data_path,i) for i in test_data_description if '.xml' in i]\n",
    "test_image_file_paths = [os.path.join(test_data_path,i) for i in test_data_description if '.jpg' in i]\n",
    "\n",
    "print(f'length of training Data {len(train_image_file_paths)}, length of test data {len(test_image_file_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4126d0-a638-45e8-a080-b6749f5cf3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Creating required directories to labels\"\"\"\n",
    "    \n",
    "for i in ['train/labels','test/labels']:\n",
    "    directory_name = os.path.join('./datasets/dataset_VOC/',i)\n",
    "    if os.path.exists(directory_name):\n",
    "        shutil.rmtree(directory_name)\n",
    "    os.makedirs(directory_name)\n",
    "    \n",
    "\"\"\"Copying all images to required directories\"\"\"\n",
    "copytree(train_data_path,'./datasets/dataset_VOC/train/images/',ignore = ignore_patterns('*.xml'))\n",
    "copytree(test_data_path,'./datasets/dataset_VOC/test/images/',ignore = ignore_patterns('*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d224b0-37da-4d4f-bdbf-cb947308c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'aeroplane':0, 'bicycle':1, 'boat':2, 'bus':3, \n",
    "              'car':4, 'motorbike':5, 'train':6, 'bird':7, \n",
    "              'cat':8, 'cow':9, 'dog':10, 'horse':11, 'sheep':12,'person':13,\n",
    "             'bottle':14, 'chair':15, 'dining table':16, 'potted plant':17, 'sofa':18, 'tv/monitor':19}\n",
    "\n",
    "dest_path = './datasets/dataset_VOC/train/labels/'\n",
    "for i in train_annotation_file_paths:\n",
    "    convert_xml_to_txt(train_data_path,i,class_dict,dest_path)\n",
    "dest_path = './datasets/dataset_VOC/test/labels/'\n",
    "for i in test_annotation_file_paths:\n",
    "    convert_xml_to_txt(test_data_path,i,class_dict,dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78cc4b-6fc9-4b10-a8fc-b2164767af80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the pre-trained version of YOLO8 on Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570187f1-f9a5-4a03-bdb8-92cbddce3312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \"\"\"yaml file path, you can check the file\"\"\"\n",
    "yaml_path = \"./data_VOC.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221b9a1-5bbc-4294-9ce5-8423b27e42be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd95419-1fe8-4810-b291-eb5602e38620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Training model'''\n",
    "results = model.train(data=yaml_path, epochs=500, batch=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60953c90-c8d2-4f5a-8c8b-b69daf5e543c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e62881-a395-441c-8341-81b1673ea218",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the model'''\n",
    "model = YOLO('./train2/weights/best.pt')\n",
    "img_dict = {  0: 'aeroplane',  1: 'bicycle',  2: 'boat',  3: 'bus',  4: 'car',  5: 'motorbike',  6: 'train',  \n",
    "            7: 'bird',  8: 'cat',  9: 'cow',  10:'dog' , 11:'horse',  12:'sheep',  13:'person',  14:'bottle',  15:'chair',  16:'dining table',\n",
    "            17:'potted plant',  18:'sofa',  19:'tv/monitor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d583ade-021d-4834-9ae9-ee5bfc91a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the images from each type of apples, bananas, oranges, and mixed fruits'''\n",
    "path_img = './datasets/dataset_VOC/test_zip/test/000004.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "colors = ['r','y','b']\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e9425-dbc4-4c46-bdd3-4d79ce2788ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the images from each type of apples, bananas, oranges, and mixed fruits'''\n",
    "path_img = './datasets/dataset_VOC/test_zip/test/000069.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "colors = ['r','y','b']\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450a66a-58b7-4949-b9fe-96743c45a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the images from each type of apples, bananas, oranges, and mixed fruits'''\n",
    "path_img = './datasets/dataset_VOC/test_zip/test/000185.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "colors = ['r','y','b']\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473264db-ddc1-4a99-a700-7d12bb680957",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the images from each type of apples, bananas, oranges, and mixed fruits'''\n",
    "path_img = './datasets/dataset_VOC/test_zip/test/000297.jpg'\n",
    "image = np.array(Image.open(path_img))\n",
    "image_results = model(path_img)\n",
    "confi_lvl_cut = 0.2\n",
    "colors = ['r','y','b']\n",
    "for bbox in image_results[0].boxes.data.tolist():\n",
    "    x1, y1, x2, y2,confidence,label = bbox\n",
    "    if confidence>=confi_lvl_cut:\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, img_dict[int(label)], (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
